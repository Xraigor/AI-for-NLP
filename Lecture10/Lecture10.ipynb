{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SPAM搜索引擎垃圾技术"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    流派：\n",
    "    1.Frequency\n",
    "    2.Priority\n",
    "    \n",
    "    贝叶斯认为先前发生的事情会对后面发生的事情产生影响(Frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    贝叶斯推理：\n",
    "    1.样本足够大\n",
    "    2.确实存在\n",
    "    3.OOV问题(out of vocabulary) 对于没有出现的词，给予一个足够小的概念概率\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    垃圾邮件检测思路的扩展：\n",
    "        1.购物推荐\n",
    "        2.文本分类\n",
    "        3.生病判断"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayesian Classifier(朴素贝叶斯分类)\n",
    "\n",
    "    可解释性很弱\n",
    "\n",
    "Probability Graph Model(概率图模型)\n",
    "    \n",
    "    推理系统(增强解释性)：\n",
    "        看病\n",
    "        法律\n",
    "        金融"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    深度学习\n",
    "    1.可解释性很差，很难改进，只能加大训练量\n",
    "    2.无法解决推理问题，只能做分类与函数拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "智能：完形填空推理，阅读理解推理 ===》文本相似度判断(现在做的tf-idf,word2vec)\n",
    "    \n",
    "    当问题不存在时，无法做出推理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayes & Gaussian Bayesian Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(elements):\n",
    "    counter = Counter(elements)\n",
    "    probabilities = [counter[e] / len(elements) for e in elements]\n",
    "    return -sum(p * np.log10(p) for p in probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy([1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4316271552006655"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy([1,1,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_data = {\n",
    "    'gender':['F','F','F','F','M','M','M'],\n",
    "    'income':['+10','-10','+10','+10','+10','+10','-10'],\n",
    "    'family_number':[1,1,2,1,1,1,2],\n",
    "    'bought':[1,1,1,0,0,0,1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame.from_dict(mock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>income</th>\n",
       "      <th>family_number</th>\n",
       "      <th>bought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>+10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>-10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>+10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>+10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M</td>\n",
       "      <td>-10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender income  family_number  bought\n",
       "0      F    +10              1       1\n",
       "1      F    -10              1       1\n",
       "2      F    +10              2       1\n",
       "3      F    +10              1       0\n",
       "4      M    +10              1       0\n",
       "5      M    +10              1       0\n",
       "6      M    -10              2       1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(mock_data['family_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_split_1 = dataset[dataset['family_number'] == 1]['bought'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_split_2 = dataset[dataset['family_number'] != 1]['bought'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7176797562470717"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(sub_split_1) + entropy(sub_split_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender', 'income', 'family_number', 'bought']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_the_min_spliter(training_data: pd.DataFrame, target: str) -> str:\n",
    "    x_fields = set(training_data.columns.tolist()) - {target}\n",
    "    \n",
    "    spliter = None\n",
    "    min_entropy = float('inf')\n",
    "    \n",
    "    for f in x_fields:\n",
    "        elements = set(training_data[f])\n",
    "        for e in elements:\n",
    "            sub_spliter_1 = training_data[dataset[f] == e][target].tolist()\n",
    "            entropy_1 = entropy(sub_spliter_1)\n",
    "            sub_spliter_2 = training_data[dataset[f] != e][target].tolist()\n",
    "            entropy_2 = entropy(sub_spliter_2)\n",
    "            entropy_v = entropy_1 + entropy_2\n",
    "            \n",
    "            if entropy_v < min_entropy:\n",
    "                min_entropy = entropy_v\n",
    "                spliter = {f, e}\n",
    "                \n",
    "    print('spliter is: {}'.format(spliter))\n",
    "    print('the min entropy is: {}'.format(min_entropy))\n",
    "    \n",
    "    return spliter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spliter is: {'income', '+10'}\n",
      "the min entropy is: 0.7176797562470717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'+10', 'income'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_the_min_spliter(dataset,'bought')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "    1.Create a ‘bootstrapped' data set\n",
    "    (sklearn.tree.export_graphviz)\n",
    "    大量特征时，随机选取特征进行classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.ensemble.RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "    基于决策树的更好的一种方法\n",
    "    An Excellent for kaggle.\n",
    "#### GBDT全梯度下降算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 论文导读\n",
    "    state-of-the-art 最优秀的\n",
    "    benchmarks 标准数据集上的结果\n",
    "    nutshell "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster聚类分析\n",
    "    1.Hierachy Cluster(层级聚类)\n",
    "    2.K-mean Cluster\n",
    "    3.Embedding Cluster(类似于图神经网络，构建成向量聚类)\n",
    "    word2vec词向量可以看成最简单的图神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.cluster.KMeans\n",
    "\n",
    "    1.|D|*|K|次运算 运算量过大O((D)*(K)*n)\n",
    "    2.初始随机点的选择对于最终结果影响很大\n",
    "    3.部分图形不适用(坐标变换成适用图形)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了SVM 手撸其他算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
